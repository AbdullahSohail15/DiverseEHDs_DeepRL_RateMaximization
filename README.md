In the rapidly evolving landscape of advanced wireless networks, self-sustainable Internet-of-things (IoT) networks
become pivotal, necessitating to seamlessly accommodate additional resource-limited devices into the existing wireless infrastructures. To this end, this paper considers an IoT scenario with a wireless-powered communication network (WPCN)
where a resource-constrained secondary node (SN) with energy
harvesting (EH) capabilities harvests energy from the ambient
radio-frequency (RF) signals to meet its energy requirements.
Notably, we introduce RFEH diversity-combining techniques,
such as equal gain combining (EGC), maximum ratio combining
(MRC), and selection combining (SC) tailored for linear EH
models. To mitigate the spectrum scarcity, the SN employs a
quality of service (QoS)–aware non-orthogonal multiple access
(NOMA) scheme to opportunistically transmit data within the
uplink transmissions of the primary devices (PDs) operating
around. Aiming to maximize the sum rate of the SN, we jointly
optimize the EH time and transmit power of the SN using deep
reinforcement learning (DRL). Particularly, we implement a set
of DRL and non-DRL algorithms to see the robustness of these
algorithms in diverse RFEH diversity-combining environment
settings. Simulation results demonstrated the influence of diverse
combining techniques on the sum rate performance of the SN in
dynamic environments, providing valuable insights into their role
in optimizing SN performance under dynamic EH environments.
Keywords– Internet-of-things (IoT), wireless-powered communication network (WPCN), RF energy harvesting, diversitycombining, non-orthogonal multiple access (NOMA), and deep
reinforcement learning (DRL).
